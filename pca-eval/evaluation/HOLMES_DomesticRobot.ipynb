{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6FR9hytRrGVp"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "headers = {\n",
        "    'Authorization': 'Bearer <OPEN_AI_KEY>',\n",
        "    'Content-Type': 'application/json',\n",
        "}\n",
        "MODEL_TYPE = \"gpt-3.5-turbo-0613\" # gpt-4\n",
        "examples = json.load(open(\"/PCA-EVAL/pca-eval/data/v1.0/Domestic Robot/meta_data.json\",\"r\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "esxpRad42Z7g"
      },
      "outputs": [],
      "source": [
        "def format_choices(choices):\n",
        "    # example: ['Phoenix', 'Baton Rouge', 'Honolulu', 'Cheyenne'] -> \"(A) Phoenix. (B) Baton Rouge. (C) Honolulu. (D) Cheyenne.\"\n",
        "    return \" \".join([f\"({chr(ord('A') + i)}) {choice}\" for i, choice in enumerate(choices)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-xQxDI4sH81"
      },
      "outputs": [],
      "source": [
        "start_prompt = \"\"\"\n",
        "You are a professional multimodal embodied reasoner. Your are assisted with multiple visual api which can answer your questions about an  image. Your job is to select the best action to answer my question based on an  image.  Note that you can't directly see the image but through the answer of API. I will first give you the description of valid APIs and then give you the question. You can gather information from the api when giving the answer.\n",
        "\"\"\"\n",
        "\n",
        "api_prompt = \"\"\"#API Description\n",
        "def object_detection():\n",
        "    \\\"\"\"\n",
        "    Detects objects in current view, which you don't need do find.\n",
        "    :return: list of detected objects, e.g. ['chair','table']\n",
        "    \\\"\"\"\n",
        "    pass\n",
        "\n",
        "def list_items_in_hands():\n",
        "    \\\"\"\"\n",
        "    Lists items in your hand, which you don't need to pick up\n",
        "    :return: list of items in hand, e.g. ['coffee cup','milk']\n",
        "    \\\"\"\"\n",
        "    pass\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSTxp7-rmejY",
        "outputId": "df15988d-49b2-471d-cdef-c4d05ac3ad91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "#API Description\n",
            "def object_detection():\n",
            "    \"\"\"\n",
            "    Detects objects in current view, which you don't need do find.\n",
            "    :return: list of detected objects, e.g. ['chair','table']\n",
            "    \"\"\"\n",
            "    pass\n",
            "\n",
            "def list_items_in_hands():\n",
            "    \"\"\"\n",
            "    Lists items in your hand, which you don't need to pick up\n",
            "    :return: list of items in hand, e.g. ['coffee cup','milk']\n",
            "    \"\"\"\n",
            "    pass\n"
          ]
        }
      ],
      "source": [
        "print(api_prompt)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2JmnML3vmgS"
      },
      "source": [
        "# 新段落"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1V4wls_c0Tjh"
      },
      "outputs": [],
      "source": [
        "def chat_domestic(example_json,model=\"gpt-4\"):\n",
        "    goal_prompt = example_json['question']\n",
        "    actions_str = format_choices(example_json['actions'])\n",
        "\n",
        "\n",
        "\n",
        "    objects = str(example_json['api_cached_results']['object_detection_alfred'])\n",
        "    items = str(example_json['api_cached_results']['list_items_in_hand_alfred'])\n",
        "\n",
        "\n",
        "    request = {\n",
        "    \"model\": model,\n",
        "    \"messages\": [\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": start_prompt\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"assistant\",\n",
        "      \"content\": \"Sure, please provide me with the description of the valid APIs and your question.\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": api_prompt\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\": \"Thank you for providing the descriptions of the valid APIs. Please go ahead and ask your question so that I can assist you in selecting the best action based on the image.\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"You are a domestic robot that helps me do housework in the simulation room. Your goal is to {} Based on current condition, what is the best action to do next? {}\".format(goal_prompt,actions_str)\n",
        "    },\n",
        "    ]\n",
        "    }\n",
        "\n",
        "    api_call_history = {\n",
        "        \"object_detection\":0,\n",
        "        \"list_items_in_hands\":0,\n",
        "    }\n",
        "\n",
        "    while True:\n",
        "\n",
        "      while True:\n",
        "        try:\n",
        "          response = requests.post('https://api.openai.com/v1/chat/completions',\n",
        "                         headers=headers,\n",
        "                         data=json.dumps(request))\n",
        "\n",
        "          model_response_json = json.loads(response.text)['choices'][0]['message']\n",
        "\n",
        "          break\n",
        "        except Exception as e:\n",
        "          continue\n",
        "\n",
        "\n",
        "      # check whether api call exists in the last response\n",
        "\n",
        "\n",
        "\n",
        "      print(model_response_json)\n",
        "\n",
        "      request['messages'].append(model_response_json)\n",
        "\n",
        "      api_response = \"\"\n",
        "      has_api_call = 0\n",
        "\n",
        "      if \"object\" in model_response_json['content'] and \"detection\" in model_response_json['content'] and not api_call_history['object_detection']:\n",
        "        api_response += \"object_detection() = \"+objects+\"\\n\"\n",
        "        has_api_call = 1\n",
        "        api_call_history['object_detection'] = 1\n",
        "\n",
        "\n",
        "      if \"list_items_in_hands\" in model_response_json['content'] and not api_call_history['list_items_in_hands']:\n",
        "        api_response += \"list_items_in_hands() = \"+items+\"\\n\"\n",
        "        has_api_call = 1\n",
        "        api_call_history['list_items_in_hands'] = 1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      request['messages'].append({\n",
        "          \"role\":\"user\",\n",
        "          \"content\":api_response\n",
        "      })\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      if not has_api_call:\n",
        "        break\n",
        "\n",
        "\n",
        "\n",
        "    return request"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7X9SF-Av_cJ2",
        "outputId": "b061cd91-baef-4e6e-facd-976cf6c0b16b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'version': '1.0',\n",
              " 'domain': 'Domestic Robot',\n",
              " 'index': 0,\n",
              " 'image': 'FloorPlan10_Rotation_3.png',\n",
              " 'question': 'fry eggs',\n",
              " 'actions': ['Start the stoveburner to heat the pan',\n",
              "  'Put eggs into Microwave',\n",
              "  'Break the eggs and pour into the pan',\n",
              "  'Start the induction cooker to heat the pan',\n",
              "  'Find eggs',\n",
              "  'Pick up eggs'],\n",
              " 'anwser_index': 0,\n",
              " 'reason': \"We don't need to find or pick up eggs since we already hold them in hands. We need to use pan instead of microwave to fry eggs. We must heat the pan before frying eggs. There are only stoveburner can served as heat source (there are no induction cooker)\",\n",
              " 'key_concept': ['stoveburner', 'pan', 'eggs'],\n",
              " 'api_cached_results': {'object_detection_alfred': ['CounterTop',\n",
              "   'PepperShaker',\n",
              "   'Spatula',\n",
              "   'Pan',\n",
              "   'StoveKnob',\n",
              "   'StoveBase1',\n",
              "   'StoveTopDoor1',\n",
              "   'CoffeeMachine',\n",
              "   'Cabinet',\n",
              "   'Cup',\n",
              "   'Window',\n",
              "   'WindowStructure',\n",
              "   'StoveBurner',\n",
              "   'StoveTopGas',\n",
              "   'Microwave',\n",
              "   'SaltShaker',\n",
              "   'Drawer',\n",
              "   'PaperTowelRoll'],\n",
              "  'list_items_in_hand_alfred': ['eggs']}}"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "examples[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zkbNRykT3ByA"
      },
      "outputs": [],
      "source": [
        "model_answers = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ONkcjv6J57pD"
      },
      "outputs": [],
      "source": [
        "for i in tqdm(examples):\n",
        "  model_answers.append(chat_domestic(i,MODEL_TYPE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yMA-74PfUA-x"
      },
      "outputs": [],
      "source": [
        "with open(\"robot_chatgpt_3.5_answer_full_dialog.json\",\"w\") as f:\n",
        "  json.dump(model_answers,f,indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GFuEywIkSlUR"
      },
      "outputs": [],
      "source": [
        "#assert len(model_answers) == len(examples)\n",
        "\n",
        "# write answers\n",
        "outputs = []\n",
        "\n",
        "for i,j in enumerate(model_answers):\n",
        "  outputs.append({\"index\":i,\"model_output\":j['messages'][-2]['content']})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_cIqRIW5-3H"
      },
      "outputs": [],
      "source": [
        "with open(\"robot_chatgpt_3.5_answer.json\",\"w\") as f:  # for automatic evaluation\n",
        "  json.dump(outputs,f,indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FxxAI3YOTMrl"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
