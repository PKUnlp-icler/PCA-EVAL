{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6FR9hytRrGVp"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "headers = {\n",
        "    'Authorization': 'Bearer <OPEN_AI_KEY>',\n",
        "    'Content-Type': 'application/json',\n",
        "}\n",
        "MODEL_TYPE = \"gpt-3.5-turbo-0613\" # gpt-4\n",
        "examples = json.load(open(\"/PCA-EVAL/pca-eval/data/v1.0/Open-World Game/meta_data.json\",\"r\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "esxpRad42Z7g"
      },
      "outputs": [],
      "source": [
        "def format_choices(choices):\n",
        "    # example: ['Phoenix', 'Baton Rouge', 'Honolulu', 'Cheyenne'] -> \"(A) Phoenix. (B) Baton Rouge. (C) Honolulu. (D) Cheyenne.\"\n",
        "    return \" \".join([f\"({chr(ord('A') + i)}) {choice}\" for i, choice in enumerate(choices)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "g-xQxDI4sH81"
      },
      "outputs": [],
      "source": [
        "start_prompt = \"\"\"You are a professional multimodal embodied reasoner. Your are assisted with multiple visual api which can answer your questions about an  image. Your job is to select the best action to answer my question based on an image.  Note that you can't directly see the image but through the answer of API. I will first give you the description of valid APIs and then give you the question. You can gather information from the api when giving the answer. Note that you can craft an item only if you have all needed materials.\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Z8p8YWbTUrbW"
      },
      "outputs": [],
      "source": [
        "api_prompt = \"\"\"#API Description\n",
        "def list_nearby_mobs_in_minecraft():\n",
        "    \\\"\"\"\n",
        "    Lists nearby mobs in Minecraft.\n",
        "    :return: list of nearby mobs, e.g. ['creeper', 'pig']\n",
        "    \\\"\"\"\n",
        "    pass\n",
        "\n",
        "def list_inventory_information():\n",
        "    \\\"\"\"\n",
        "    Lists inventory information of the player in Minecraft.\n",
        "    :return: list of inventory information with number, e.g. [('diamond', 64), ('iron', 32)]\n",
        "    \\\"\"\"\n",
        "    pass\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSTxp7-rmejY",
        "outputId": "973d2196-d5c8-485f-fe02-bbf9e3afffe0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "#API Description\n",
            "def list_nearby_mobs_in_minecraft():\n",
            "    \"\"\"\n",
            "    Lists nearby mobs in Minecraft.\n",
            "    :return: list of nearby mobs, e.g. ['creeper', 'pig']\n",
            "    \"\"\"\n",
            "    pass\n",
            "\n",
            "def list_inventory_information():\n",
            "    \"\"\"\n",
            "    Lists inventory information of the player in Minecraft.\n",
            "    :return: list of inventory information with number, e.g. [('diamond', 64), ('iron', 32)]\n",
            "    \"\"\"\n",
            "    pass\n"
          ]
        }
      ],
      "source": [
        "print(api_prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2JmnML3vmgS"
      },
      "source": [
        "# 新段落"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "1V4wls_c0Tjh"
      },
      "outputs": [],
      "source": [
        "def chat_minecraft(example_json,model=\"gpt-4\"):\n",
        "    goal_prompt = example_json['question']\n",
        "    actions_str = format_choices(example_json['actions'])\n",
        "    answer = example_json['answer_index']\n",
        "\n",
        "    inventory = example_json['api_cached_result']['list_items_in_inventory']\n",
        "    nearby_mobs = example_json['api_cached_result']['list_nearby_mobs']\n",
        "\n",
        "\n",
        "\n",
        "    request = {\n",
        "    \"model\": model,\n",
        "    \"messages\": [\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": start_prompt\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"assistant\",\n",
        "      \"content\": \"Sure, please provide me with the description of the valid APIs and your question.\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": api_prompt\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\": \"Thank you for providing the descriptions of the valid APIs. Please go ahead and ask your question so that I can assist you in selecting the best action based on the image.\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"Question: You are a powerful game assistant in Minecraft. Your goal is to {}. Based on current condition, what is the best action to do next? {}\".format(goal_prompt,actions_str)\n",
        "    },\n",
        "    ]\n",
        "    }\n",
        "\n",
        "    api_call_history = {\n",
        "        \"list_nearby_mobs_in_minecraft\":0,\n",
        "        \"list_inventory_information\":0,\n",
        "    }\n",
        "\n",
        "    while True:\n",
        "\n",
        "      while True:\n",
        "        try:\n",
        "          response = requests.post('https://api.openai.com/v1/chat/completions',\n",
        "                         headers=headers,\n",
        "                         data=json.dumps(request))\n",
        "          model_response_json = json.loads(response.text)['choices'][0]['message']\n",
        "          break\n",
        "        except Exception as e:\n",
        "          print(response.text)\n",
        "          continue\n",
        "\n",
        "\n",
        "      # check whether api call exists in the last response\n",
        "\n",
        "\n",
        "      print(model_response_json)\n",
        "\n",
        "      request['messages'].append(model_response_json)\n",
        "\n",
        "      api_response = \"\"\n",
        "      has_api_call = 0\n",
        "\n",
        "      if \"list_nearby_mobs_in_minecraft\" in model_response_json['content'] and not api_call_history['list_nearby_mobs_in_minecraft']:\n",
        "        api_response += \"list_nearby_mobs_in_minecraft() = \"+str(nearby_mobs)+\"\\n\"\n",
        "        has_api_call = 1\n",
        "        api_call_history['list_nearby_mobs_in_minecraft'] = 1\n",
        "\n",
        "\n",
        "      if \"list_inventory_information\" in model_response_json['content'] and not api_call_history['list_inventory_information']:\n",
        "        api_response += \"list_inventory_information() = \"+str(inventory)+\"\\n\"\n",
        "        has_api_call = 1\n",
        "        api_call_history['list_inventory_information'] = 1\n",
        "\n",
        "      request['messages'].append({\n",
        "          \"role\":\"user\",\n",
        "          \"content\":api_response\n",
        "      })\n",
        "\n",
        "      if not has_api_call:\n",
        "        break\n",
        "\n",
        "\n",
        "\n",
        "    return request"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-xoFrzoc3Du5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7X9SF-Av_cJ2",
        "outputId": "6ed03986-7da9-4b72-9a6f-d49a65bd68f1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'version': '1.0',\n",
              " 'domain': 'Open-World Game',\n",
              " 'index': 0,\n",
              " 'image': 'minecraft_0.png',\n",
              " 'question': 'Harvest wool',\n",
              " 'actions': ['find sheep',\n",
              "  'shear sheep',\n",
              "  'craft shears',\n",
              "  'find iron ore',\n",
              "  'craft iron ingot'],\n",
              " 'answer_index': 3,\n",
              " 'reason': \"To get wool, you need to find a sheep, and use shears to get the wool. There is sheep nearby, but you don't have shears, so you need to craft shears first. To craft shears, you need two iron ingots. You don't have iron ingot, so you need to find iron ore first to craft iron ingot.\",\n",
              " 'key_concept': ['Sheep nearby', 'No shears', 'No iron ingot'],\n",
              " 'api_cached_result': {'list_nearby_mobs': ['sheep'],\n",
              "  'list_items_in_inventory': []}}"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "examples[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "zkbNRykT3ByA"
      },
      "outputs": [],
      "source": [
        "model_answers = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqokewYNC35Q",
        "outputId": "03fc82e5-babf-4f95-f39d-7daa715f6d71"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(model_answers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ONkcjv6J57pD"
      },
      "outputs": [],
      "source": [
        "for i in tqdm(examples[:100]):\n",
        "  model_answers.append(chat_minecraft(i,MODEL_TYPE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_cIqRIW5-3H"
      },
      "outputs": [],
      "source": [
        "with open(\"minecraft_chatgpt_3.5_answer_full_dialog.json\",\"w\") as f:\n",
        "  json.dump(model_answers,f,indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "assert len(model_answers) == len(examples)\n",
        "\n",
        "# write answers\n",
        "outputs = []\n",
        "\n",
        "for i,j in enumerate(model_answers):\n",
        "  outputs.append({\"index\":i,\"model_output\":j['messages'][-2]['content']})\n",
        "\n",
        "with open(\"minecraft_chatgpt_3.5_answer.json\",\"w\") as f:  # used for automatic evaluation\n",
        "  json.dump(outputs,f,indent=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Simple Parsing for Action Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LpvB88wA52Yj"
      },
      "outputs": [],
      "source": [
        "def chat_parse_answer(example_json,model_answer,model=\"gpt-3.5-turbo-0613\"):\n",
        "\n",
        "    actions_str = format_choices(example_json['actions'])\n",
        "    request = {\n",
        "    \"model\": model,\n",
        "    \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": \"You are going to help me parse the model output into the options. I will give you the option list and the model output, you need to answer which option does the model output imply and respond in json format like {\\\"model_output\\\":\\\"A\\\"} , if the answer does not match with any option, or the modal can't make any option right now, just output {\\\"model_output\\\":\\\"None\\\"}. \"},\n",
        "            {\"role\": \"assistant\", \"content\": \"Sure, I will output the correct json return based on model's output.\"},\n",
        "            {\"role\": \"user\", \"content\": \"Options:%s \\n Model Output:%s\"%(actions_str,model_answer)},\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    while True:\n",
        "      try:\n",
        "        response = requests.post('https://api.openai.com/v1/chat/completions',\n",
        "                        headers=headers,\n",
        "                        data=json.dumps(request))\n",
        "        break\n",
        "      except Exception as e:\n",
        "        continue\n",
        "\n",
        "\n",
        "      # check whether api call exists in the last response\n",
        "\n",
        "    model_response_json = json.loads(response.text)['choices'][0]['message']\n",
        "\n",
        "\n",
        "    return model_response_json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMbP9SI39Zxn",
        "outputId": "2dff4be9-08d6-46e2-e695-da838254f5b9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'role': 'assistant', 'content': '{\"model_output\":\"B\"}'}"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chat_parse_answer(examples[0],model_answers[0]['messages'][-2]['content'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-O0BeFa94KU"
      },
      "outputs": [],
      "source": [
        "parsed_answer=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNred9XJxuW_",
        "outputId": "c7d407d4-e8dd-452f-a1c9-3ac6a4a9e767"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(model_answers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijfERxpEutj9",
        "outputId": "6e244cd4-2ce7-4a48-ad79-348ee23c0dab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(parsed_answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqTMfeE89iBR"
      },
      "outputs": [],
      "source": [
        "for i,j in zip(examples[:100],model_answers[:100]):\n",
        "  model_answer = j['messages'][-2]['content']\n",
        "  parsed_result = chat_parse_answer(i,j['messages'][-2]['content'])\n",
        "  action_list = format_choices(i['actions'])\n",
        "  answer = i['answer_index']\n",
        "  key_concept = i['key_concept']\n",
        "  reason = i['reason']\n",
        "\n",
        "  parsed_answer.append({\n",
        "      \"model_answer\":model_answer,\n",
        "      \"parsed_result\":parsed_result,\n",
        "      \"action_list\":action_list,\n",
        "      \"answer\":chr(ord('A') + answer),\n",
        "      \"key_concept\":key_concept,\n",
        "      \"reason\":reason\n",
        "  })\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PzLavfngOEoU"
      },
      "outputs": [],
      "source": [
        "with open(\"minecraft_v1_gpt3.5_answer_parsed.json\",\"w\") as f:\n",
        "  json.dump(parsed_answer,f,indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HyK1XtQCxHGD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0o4Gk44BrbC"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def extract_substrings(s):\n",
        "    return re.findall(r'\\{.*?\\}', s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WPSCm2Lj--l2"
      },
      "outputs": [],
      "source": [
        "rough_correct = 0\n",
        "for index, i in enumerate(parsed_answer):\n",
        "  parsed_dict = extract_substrings(i['parsed_result']['content'])\n",
        "  if len(parsed_dict)!=0:\n",
        "    try:\n",
        "      print(index+1, i['answer'],eval(parsed_dict[0]), int(i['answer']==eval(parsed_dict[0])['model_output']),sep=\" | \")\n",
        "      if i['answer']==eval(parsed_dict[0])['model_output']:\n",
        "        rough_correct+=1\n",
        "    except:\n",
        "      print(index+1, i['answer'], i['parsed_result']['content'].replace(\"\\n\",\"\")+\"$\",0,sep=\" | \")\n",
        "  else:\n",
        "    print(index+1, i['answer'], i['parsed_result']['content'].replace(\"\\n\",\"\")+\"$\",0,sep=\" | \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ODgGD4uDAl2"
      },
      "outputs": [],
      "source": [
        "rough_action_acc = rough_correct/100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PY3FaiwsXhuW"
      },
      "outputs": [],
      "source": [
        "rough_action_acc # 0.36 in our experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kM6kp41ZXiwM"
      },
      "outputs": [],
      "source": [
        "# the action acc could be lower than the real acc since some parsing result could be wrong, need double check to get the final results"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
